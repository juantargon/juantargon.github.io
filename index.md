<link rel="stylesheet" href="/assets/style.css">

# Data Engineer | Data Science | ML Engineer

I am a Data Engineer with experience in data ingestion, modeling, and processing across Big Data and Cloud environments.  
I previously worked at Santander TecnologÃ­a (via Datalytics) and Disbyte, where I designed large-scale pipelines, optimized ETL/ELT processes, and ensured data quality, performance, and consistency.  

I am currently pursuing a Masterâ€™s in Economics, Finance, and Computation (UNIA), focusing on Big Data, AI, and applied analytics.

---

## ğŸš€ Skills

**Data Engineering:** PySpark, Spark, Airflow, ETL/ELT, Data Modeling, Data Lake  
**Cloud:** AWS (Lambda, Redshift, S3, RDS, Aurora, API Gateway, SNS, SQS, IAM)  
**Databases:** SQL, PL/SQL, PostgreSQL, Oracle, MongoDB, DynamoDB  
**Programming:** Python (Pandas, Polars, APIs, automation)  
**Tools:** Hive, Git/GitLab, Jira, Postman  
**Methodologies:** CI/CD, data quality, orchestration, scalable design  

---

## ğŸ’¼ Work Experience

### **Data Engineer â€” Datalytics / Santander Technology**  
**05/2023 â€“ 05/2025 | Argentina**

- Member of the core data ingestion team for Santanderâ€™s Data Lake.  
- Designed and modeled data structures following domain standards and business requirements.  
- Built and optimized ingestion processes using PySpark and Airflow.  
- Ensured reliability, availability, and traceability of data assets.

**Achievements:**
- Reduced data ingestion times by **30%** through pipeline optimization.  
- Built standardized data models improving usability and analytical traceability.  
- Proposed automations and improvements for ETL processes and data quality validations.

---

### **Data Engineer â€” Disbyte (E-commerce)**  
**05/2025 â€“ 10/2025 | Argentina**

- Designed and implemented ingestion and processing pipelines from APIs, transactional DBs, and external platforms.  
- Contributed to defining a scalable data architecture in AWS for both analytical and operational use.  
- Optimized ELT workflows using Spark, Pandas, and Polars.  
- Worked closely with business teams to gather requirements and validate deliverables.

**Achievements:**
- Developed ingestion pipelines for Amazon, Mercado Libre, and logistics APIs into Redshift and the Data Lake.  
- Designed consistent, end-to-end data models for analytics and reporting.  
- Reduced processing times and infrastructure costs through architectural improvements.

---

## ğŸ“ Education

### **Master in Economics, Finance and Computation â€” UNIA**  
**2025 â€“ Present**  
Focus on Big Data, Applied Economics, Machine Learning, and computational tools.

### **Information Systems Engineering â€” UTN FRC**  
**2019 â€“ 2024**  
Average: **8.38** â€” GPA: **3.7**

---

## ğŸ“œ Certifications

- AWS Cloud Practitioner (2024)  
- AWS Data Engineer (in progress) (2025)  
- Apache Airflow Fundamentals â€“ Astronomer (2024)  
- Git & GitHub Professional Course (2023)  
- Tableau & Data Visualization (2022)

---

## ğŸ§  Projects

### **ğŸ“± Fitbuddy**
A system for managing training routines and performance tracking.  
Includes backend development in Python, data modeling, ingestion processes, and an analytical dashboard.  
(*If needed, I can provide a full project description, architecture diagram, and tech stack section.*)

---

## ğŸŒ Contact

**LinkedIn:** https://www.linkedin.com/in/juan-cruz-targon  
**Email:** juantargon@gmail.com  
**Location:** Barcelona, Spain  

---

